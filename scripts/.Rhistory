# Chunk 13: frqs2
# add frequencies -----------------------------------------------
lx$Freq_encow <- sapply(1:nrow(lx), function(i) sum(encow[grepw(lx$lemma[i], encow$word),]$Freq_encow))
ly$Freq_encow <- sapply(1:nrow(ly), function(i) sum(encow[grepw(ly$lemma[i], encow$word),]$Freq_encow))
# Chunk 14: discardzeros
# omit all that are not attested in ENCOW
lx <- filter(lx, Freq_encow > 0)
ly <- filter(ly, Freq_encow > 0)
# Chunk 15: collexanal
collex.dist(lx) %>% datatable() %>% formatSignif(columns = c("E.CXN1", "E.CXN2", "COLL.STR.LOGL"), digits=3)
collex.dist(ly) %>% datatable() %>% formatSignif(columns = c("E.CXN1", "E.CXN2", "COLL.STR.LOGL"), digits=3)
d %>% select(head_x, head_y) %>% as.data.frame %>% collex.covar %>% pretty_df() %>% kbl() %>%
kable_material(c("striped", "hover")) %>% scroll_box(width = "800px", height = "200px") %>% datatable()
# load "concordances"
library(concordances)
library(tidyverse)
library(readxl)
library(data.table)
library(kableExtra)
library(collostructions)
d <- getNSE("../data/mother_of_all.xml", xml = TRUE, context_tags = FALSE, verbose = FALSE)
# write_excel_csv(d, "mother_of_all_ENCOW.csv")
d <- read_xlsx("../data/mother_of_all_ENCOW.xlsx")
d <- filter(d, keep == "y")
# frequency table
d_tbl <- d %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(lemma = ".", Freq = "n")) %>% arrange(desc(Freq))
d
d %>% select(lemma) %>% table %>% as_tibble()
d %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(lemma = ".", Freq = "n"))
?rename
# frequency table
d_tbl <- d %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(Freq = "n")) %>% arrange(desc(Freq))
# overview table
tibble(
# types
Types = nrow(d_tbl),
# tokens
Tokens = sum(d_tbl$Freq),
# hapax legomena
"Hapax Legomena" = length(which(d_tbl$Freq==1))
) %>% kbl() %>% kable_material(c("striped", "hover"))
# not in repository,
# available at webcorpora.org after registration
# frequencies for relevant hits available at ../data/mother_of_all_with_encow_frequencies.csv
encow <- fread("/Volumes/My Passport/ENCOW word lists/encow16ax.lp.tsv",
header = F)
# re-import
d_tbl <- read_csv("../data/mother_of_all_with_encow_frequencies.csv")
# omit one case where corpus frequency is
# smaller than cxn frequency
d_tbl <- subset(d_tbl, d_tbl[,2] <= d_tbl[,3])
# sum(encow$Freq): 1805183579
# perform collexeme analysis
collex(d_tbl, corpsize = 1805183579) %>% kbl() %>%
kable_material(c("striped", "hover")) %>% scroll_box(width = "800px", height = "200px")
collex(d_tbl, corpsize = 1805183579) %>% kbl()
collex(d_tbl, corpsize = 1805183579)
d_tbl
# sum(encow$Freq): 1805183579
# perform collexeme analysis
collex(as.data.frame(d_tbl), corpsize = 1805183579) %>% kbl() %>%
kable_material(c("striped", "hover")) %>% scroll_box(width = "800px", height = "200px")
# read data
moa <- read_xlsx("../data/motherofall_COCA.xlsx")
# read data
moa <- read_xlsx("../data/motherofall_COCA.xlsx")
# full frequency list cannot be shared publicly
# for license reasons, hence we work with the
# list containing only the lemmas occurring in
# mother of all
#coca <- fread("../coca_2017_lemma_frequency_list.txt", quote = "")
coca <- fread("../data/coca_moa_lemma_frequencies.csv")
# replace whitespaces in column names
colnames(moa) <- gsub(" ", "_", colnames(moa))
colnames(coca) <- c("No", "Lemma", "Freq")
# omit false hits
moa <- subset(moa, keep=="y")
# types, tokens, and hapax legomena overall
moa_tbl1 <- moa %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(lemma = ".", Freq = "n") ) %>% arrange(desc(Freq))
# types, tokens, and hapax legomena overall
moa_tbl1 <- moa %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(Freq = "n") ) %>% arrange(desc(Freq))
tibble(
Tokens = sum(moa_tbl1$Freq),
Types = nrow(moa_tbl1),
"Hapax Legomena" = length(which(moa_tbl1$Freq==1))
)
# generate input for collostructional analysis
moa_lemmas <- moa$lemma %>% table %>% sort(decreasing = T) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_lemmas) <- c("Lemma", "Freq_in_cxn")
all_lemmas <- coca[,Lemma, Freq]
setcolorder(all_lemmas, c("Lemma", "Freq"))
collex_input <- join.freqs(moa_lemmas, as.data.frame(all_lemmas), all = F)
colnames(collex_input) <- c("Lemma", "cxn_freq", "cxn_all")
collex_input <- subset(collex_input, cxn_all != 0)
collex(collex_input, corpsize = sum(coca$Freq)) # %>% write_excel_csv("simple_collexeme_analysis.csv")
# relative frequency ------------------------------------------------------
# get COCA frequencies
coca_freq <- read_xlsx("../data/COCA2017_total_frequencies.xlsx")
# tabulate mother frequency
moa_tbl <- table(moa$Year) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_tbl) <- c("YEAR", "Freq")
moa_tbl$YEAR <- as.numeric(moa_tbl$YEAR)
moa_tbl <- left_join(coca_freq, moa_tbl, by = "YEAR")
moa_tbl$pmw <- (moa_tbl$Freq / moa_tbl$TOTAL) * 1e06
# plot
# png("mother_of_all_coca_freq.png", width = 6.5, height = 5, un = "in", res = 300)
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = expression(paste("[", italic("mother of all"), " X], COCA")))
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey")
# dev.off()
# types per decade
moa_types <- moa %>% group_by(Decade) %>% summarise(
types = length(unique(lemma)),
n = n()
)
# types per year
moa_types_year <- moa %>% group_by(Year) %>% summarise(
types = length(unique(lemma))
)
# add to table with total frequencies
moa_tbl <- left_join(moa_types_year, moa_tbl, by = c("Year" = "YEAR"))
moa_tbl <- rename(moa_tbl, "YEAR" = "Year")
moa_tbl$types_pmw <- (moa_tbl$types / moa_tbl$TOTAL) * 1e6
# coca_freq per dcade
coca_freq$Decade <- floor(coca_freq$YEAR/10)*10
coca_freq_decade <- coca_freq %>% group_by(Decade) %>% summarise(
n = sum(TOTAL)
)
# types per decade
moa_types <- left_join(moa_types, coca_freq_decade)
moa_types$rel <- moa_types$types / moa_types$n
moa_types$rel %>% plot
moa_types$ttr <- moa_types$types / moa_types$n
# distribution of hapaxes
hapaxes <- table(moa$lemma) %>% as.data.frame %>% filter(Freq==1) %>% select(Var1) %>% as.vector
hapaxes <- as.character(hapaxes$Var1)
moa$hapax <- ifelse(moa$lemma %in% hapaxes, "y", "n")
moa_hapaxes <- moa %>% group_by(Decade) %>% summarise(
hapaxes = length(which(hapax=="y")),
n = n()
)
# plot potential productivity
moa_hapaxes$pp <- moa_hapaxes$hapaxes / moa_hapaxes$n
par(mfrow = c(1,3))
#png("types_tokens_mother_COCA.png", width = 12, height = 4, un = "in", res = 300)
par(mfrow=c(1,3))
par(mar = c(5.1, 5.1, 5.1, 2.1))
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = expression(paste(bold("["), bolditalic("mother of all"), bold(" X], COCA"))),
cex = 2, cex.lab = 2, cex.axis=1.5)
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey", lwd = 2)
points(moa_tbl$YEAR, moa_tbl$types_pmw, col = rgb(1,0,0,.5), pch = 18, cex = 1.3)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5)
# dev.off()
par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(1,1))
?axos
?axis
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5, xaxt = "n")
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5,
#xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010))
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5,
#xaxt = "n"
)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010))
axis(1, at = c(1990, 2000, 2010), cex = 2)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
axis(1, at = c(1990, 2000, 2010), cex.axis=1.5)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2,
xaxt = "n"
)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2, xaxt = "n")
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
par(mfrow = c(1,3))
#png("types_tokens_mother_COCA.png", width = 12, height = 4, un = "in", res = 300)
par(mfrow=c(1,3))
par(mar = c(5.1, 5.1, 5.1, 2.1))
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = expression(paste(bold("["), bolditalic("mother of all"), bold(" X], COCA"))),
cex = 2, cex.lab = 2, cex.axis=1.5)
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey", lwd = 2)
points(moa_tbl$YEAR, moa_tbl$types_pmw, col = rgb(1,0,0,.5), pch = 18, cex = 1.3)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2, xaxt = "n")
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
# dev.off()
par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(1,1))
par(mfrow = c(1,3))
png("types_tokens_mother_COCA.png", width = 12, height = 4, un = "in", res = 300)
par(mfrow=c(1,3))
par(mar = c(5.1, 5.1, 5.1, 2.1))
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = expression(paste(bold("["), bolditalic("mother of all"), bold(" X], COCA"))),
cex = 2, cex.lab = 2, cex.axis=1.5)
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey", lwd = 2)
points(moa_tbl$YEAR, moa_tbl$types_pmw, col = rgb(1,0,0,.5), pch = 18, cex = 1.3)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2, xaxt = "n")
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
dev.off()
par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(1,1))
# install CRAN packages (if not yet installed)
sapply(c("data.table", "tidyverse", "devtools", "readxl", "kableExtra", "ngram", "networkD3", "igraph", "network", "patchwork", "koRpus", "pbapply", "tidytext", "cluster", "ggrepel", "animation"), function(x) if(!is.element(x, installed.packages())) install.packages(x, dependencies = T))
# load packages
library(readxl)
library(tidyverse)
library(ngram)
library(networkD3)
library(igraph)
library(network)
library(patchwork)
library(koRpus)
library(pbapply)
library(tidytext)
library(cluster)
library(ggrepel)
library(animation)
library(kableExtra)
library(DT)
library(collostructions) # available at sflach.ch
library(concordances) #available at github.com/hartmast/concordances
library(wizard) # available at github.com/hartmast/wizard
# logarithmize and return 0 instead of Inf if x==0
log0 <- function(x) {
x <- ifelse(x == 0, 0, log(x))
return(x)
}
# function for "prettyfying" df output
# inspired by https://github.com/rmcelreath/rethinking/blob/d0978c7f8b6329b94efa2014658d750ae12b1fa2/R/utilities.r
pretty_df <- function(df) {
# function for rounding
round_this <- function(x, digits = 2) ifelse(x < 1, signif(x, digits = digits), round(x, digits = 2))
# function for getting prettyfied dataframe
df_pretty <- as.data.frame(lapply(1:length(df),
function(i) if(!class(df[[i]]) %in% c("character", "factor"))
{
round_this(df[[i]])
} else {
return(df[[i]])
})
)
# set names to original names
colnames(df_pretty) <- colnames(df)
return(df_pretty)
}
# search for entire words
grepw <- function(pattern, x, perl = F, ...) {
grep(paste("^", pattern, "$", sep="", collapse=""), x, perl = perl, ...)
}
d <- read_xlsx("../data/ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# exclude false hits ------------------------------------------------------
d <- filter(d, keep == "y")
# add wordcount for x and y lemmas ----------------------------------------
d$wordcount_x <- sapply(1:nrow(d), function(i) wordcount(trimws(d$Lemma_x[i])))
d$wordcount_y <- sapply(1:nrow(d), function(i) wordcount(trimws(d$Lemma_y[i])))
# get heads of compounds and phrases --------------------------------------
# find instances in which there are words
# written entirely in uppercase (= our way of
# marking heads in the data, unless in the case of
# right-hand heads)
# empty columns for heads
d$head_x <- NA; d$head_y <- NA
# add wordcount for x and y lemmas
d$wordcount_x <- sapply(1:nrow(d), function(i) wordcount(trimws(d$Lemma_x[i])))
d$wordcount_y <- sapply(1:nrow(d), function(i) wordcount(trimws(d$Lemma_y[i])))
# get heads
for(i in 1:nrow(d)) {
if(d$wordcount_x[i]>1) {
if(d$pos_x[i]!="NE" & grepl("[A-Z]{2,}", d$Lemma_x[i])) {
d$head_x[i] <- tolower(unlist(strsplit(d$Lemma_x[i], " "))[grepl("[A-Z]{2,}", unlist(strsplit(d$Lemma_x[i], " ")))][1])
} else{
temp <- unlist(strsplit(d$Lemma_x[i], " "))
d$head_x[i] <- tolower(temp[length(temp)])
}
} else {
d$head_x[i] <- tolower(d$Lemma_x[i])
}
if(d$wordcount_y[i]>1) {
if(d$pos_y[i]!="NE" & grepl("[A-Z]{2,}", d$Lemma_y[i])) {
d$head_y[i] <- tolower(unlist(strsplit(d$Lemma_y[i], " "))[grepl("[A-Z]{2,}", unlist(strsplit(d$Lemma_y[i], " ")))][1])
} else{
temp <- unlist(strsplit(d$Lemma_y[i], " "))
d$head_y[i] <- tolower(temp[length(temp)])
}
} else {
d$head_y[i] <- tolower(d$Lemma_y[i])
}
}
# remove all with "unclear" -----------------------------------------------
# backup copy for subsequent analysis
d_backup <- d
d <- d[-which(d$concept_x=="unclear" | d$concept_y=="unclear"),]
# get hapaxes:
tibble(
types_x = length(unique(d$head_x)),
types_y = length(unique(d$head_y)),
types   = length(unique(paste0(d$head_x, "/", d$head_y))),
hapaxes_x = table(d$head_x) %>% as_tibble(.name_repair = "unique") %>% setNames(c("lemma_x", "n")) %>% filter(n == 1) %>% nrow(),
hapaxes_y = table(d$head_y) %>% as_tibble(.name_repair = "unique") %>% setNames(c("lemma_y", "n")) %>% filter(n == 1) %>% nrow(),
hapaxes_all = paste0(d$head_x, "/", d$head_y) %>% table %>% as_tibble() %>% setNames(c("lemma", "n")) %>% filter(n == 1) %>% nrow,
tokens = nrow(d)
) %>% kbl()
# network ----------------------------------------------------------------
d$concept_x <- factor(d$concept_x); d$concept_y <- factor(d$concept_y)
tbl <- d %>% select(concept_x, concept_y) %>% table %>% as.data.frame
tbl$number_x <- as.numeric(factor(tbl$concept_x))
tbl$number_y <- as.numeric(factor(tbl$concept_y))
# add a column in which the frequency is 0 if
# concept_x == concept_y
tbl$Freq_noself <- ifelse(tbl$concept_x == tbl$concept_y, NA, tbl$Freq)
# sort factors by frequency in concept_x ----------------------------------
conc_by_freq <- d$concept_x %>% table %>% sort(decreasing = T) %>% rownames()
tbl$concept_x <- factor(tbl$concept_x, levels = conc_by_freq)
tbl$concept_y <- factor(tbl$concept_y, levels = conc_by_freq)
# heatmaps ----------------------------------------------------------------
tbl %>% ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq))) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
guides(fill = guide_legend(title = "LogFreq"))
( p1 <- tbl %>% filter(Freq > 0) %>% ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq), label = Freq)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq > 6), "black", "white"), size = 4) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18))
)
( p1 <- tbl %>% filter(Freq > 0) %>% ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq), label = Freq)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq > 6), "black", "white"), size = 4) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18))
) + guides(fill = 'none')
( p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) ) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18))
( p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) ) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18) + guides(fill = 'none'))
( p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) ) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18))
( p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) ) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18)) + guides(fill = "none"))
( p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) ) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18)) + guides(fill = "none")
p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) ) +
( p2 <- tbl %>% filter(Freq > 0) %>%
ggplot(aes(x = concept_x, y = concept_y, fill = log0(Freq_noself), label = Freq_noself)) +
geom_tile() + scale_fill_gradient(low = "yellow", high = "darkred") +
guides(fill = guide_legend(title = "LogFreq")) + theme_classic() +
theme(axis.text.x = element_text(angle=45, hjust=.9)) +
geom_text(col = ifelse(log(filter(tbl, Freq > 0)$Freq_noself > 6), "black", "white"), size = 4) +
theme(axis.text = element_text(size = 18)) +
theme(axis.title = element_text(size = 18)) +
theme(strip.text = element_text(size = 18)) +
theme(legend.text = element_text(size = 18)) +
theme(legend.title = element_text(size = 18, face = "bold")) +
theme(text = element_text(size = 18)) + guides(fill = "none") )
remotes::install_github("bschmidt/wordVectors")
remotes::install_github("bmschmidt/wordVectors")
remotes::install_github("bmschmidt/wordVectors")
library(wordVectors)
