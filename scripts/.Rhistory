# Chunk 7: dw
d <- filter(d, keep == "y")
# Chunk 8
# frequency table
d_tbl <- d %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(Freq = "n")) %>% arrange(desc(Freq))
# overview table
tibble(
# types
Types = nrow(d_tbl),
# tokens
Tokens = sum(d_tbl$Freq),
# hapax legomena
"Hapax Legomena" = length(which(d_tbl$Freq==1))
) %>% kbl() %>% kable_material(c("striped", "hover"))
# Chunk 13
# re-import
d_tbl <- read_csv("../data/mother_of_all_with_encow_frequencies.csv")
# Chunk 14: excludethis
# omit one case where corpus frequency is
# smaller than cxn frequency
d_tbl <- subset(d_tbl, d_tbl[,2] <= d_tbl[,3])
# Chunk 15: collex
# sum(encow$Freq): 1805183579
# perform collexeme analysis
left_join(collex(as.data.frame(d_tbl), corpsize = 1805183579, delta.p = TRUE),
select(collex(as.data.frame(d_tbl), corpsize = 1805183579, am = "odds"), COLLEX, COLL.STR.ODDS)) %>% DT::datatable()  #kbl() %>%
#kable_material(c("striped", "hover")) %>% scroll_box(width = "800px", height = "200px")
# Chunk 16
# read data
moa <- read_xlsx("../data/motherofall_COCA.xlsx")
# full frequency list cannot be shared publicly
# for license reasons, hence we work with the
# list containing only the lemmas occurring in
# mother of all
#coca <- fread("../coca_2017_lemma_frequency_list.txt", quote = "")
coca <- fread("../data/coca_moa_lemma_frequencies.csv")
# replace whitespaces in column names
colnames(moa) <- gsub(" ", "_", colnames(moa))
colnames(coca) <- c("No", "Lemma", "Freq")
# omit false hits
moa <- subset(moa, keep=="y")
# types, tokens, and hapax legomena overall
moa_tbl1 <- moa %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(Freq = "n") ) %>% arrange(desc(Freq))
tibble(
Tokens = sum(moa_tbl1$Freq),
Types = nrow(moa_tbl1),
"Hapax Legomena" = length(which(moa_tbl1$Freq==1))
)
# generate input for collostructional analysis
moa_lemmas <- moa$lemma %>% table %>% sort(decreasing = T) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_lemmas) <- c("Lemma", "Freq_in_cxn")
all_lemmas <- coca[,Lemma, Freq]
setcolorder(all_lemmas, c("Lemma", "Freq"))
collex_input <- join.freqs(moa_lemmas, as.data.frame(all_lemmas), all = F)
colnames(collex_input) <- c("Lemma", "cxn_freq", "cxn_all")
collex_input <- subset(collex_input, cxn_all != 0)
left_join(collex(collex_input, corpsize = sum(coca$Freq), delta.p = T),
select(collex(collex_input, corpsize = sum(coca$Freq), am = "odds"), COLLEX, COLL.STR.ODDS)) %>% DT::datatable()
# %>% write_excel_csv("simple_collexeme_analysis.csv")
# relative frequency ------------------------------------------------------
# get COCA frequencies
coca_freq <- read_xlsx("../data/COCA2017_total_frequencies.xlsx")
# tabulate mother frequency
moa_tbl <- table(moa$Year) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_tbl) <- c("YEAR", "Freq")
moa_tbl$YEAR <- as.numeric(moa_tbl$YEAR)
moa_tbl <- left_join(coca_freq, moa_tbl, by = "YEAR")
moa_tbl$pmw <- (moa_tbl$Freq / moa_tbl$TOTAL) * 1e06
# plot
# png("mother_of_all_coca_freq.png", width = 6.5, height = 5, un = "in", res = 300)
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = "Token and type frequencies")
#main = expression(paste("[", italic("mother of all"), " X], COCA")))
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey")
# dev.off()
# types per decade
moa_types <- moa %>% group_by(Decade) %>% summarise(
types = length(unique(lemma)),
n = n()
)
# types per year
moa_types_year <- moa %>% group_by(Year) %>% summarise(
types = length(unique(lemma))
)
# add to table with total frequencies
moa_tbl <- left_join(moa_types_year, moa_tbl, by = c("Year" = "YEAR"))
moa_tbl <- rename(moa_tbl, "YEAR" = "Year")
moa_tbl$types_pmw <- (moa_tbl$types / moa_tbl$TOTAL) * 1e6
# coca_freq per dcade
coca_freq$Decade <- floor(coca_freq$YEAR/10)*10
coca_freq_decade <- coca_freq %>% group_by(Decade) %>% summarise(
n = sum(TOTAL)
)
# types per decade
moa_types <- left_join(moa_types, coca_freq_decade)
moa_types$rel <- moa_types$types / moa_types$n
moa_types$rel %>% plot
moa_types$ttr <- moa_types$types / moa_types$n
# distribution of hapaxes
hapaxes <- table(moa$lemma) %>% as.data.frame %>% filter(Freq==1) %>% select(Var1) %>% as.vector
hapaxes <- as.character(hapaxes$Var1)
moa$hapax <- ifelse(moa$lemma %in% hapaxes, "y", "n")
moa_hapaxes <- moa %>% group_by(Decade) %>% summarise(
hapaxes = length(which(hapax=="y")),
n = n()
)
# plot potential productivity
moa_hapaxes$pp <- moa_hapaxes$hapaxes / moa_hapaxes$n
par(mfrow = c(1,3))
#png("types_tokens_mother_COCA.png", width = 12, height = 4, un = "in", res = 300)
par(mfrow=c(1,3))
par(mar = c(5.1, 5.1, 5.1, 2.1))
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = "Token and type frequencies",
#main = expression(paste(bold("["), bolditalic("mother of all"), bold(" X], COCA"))),
cex = 2, cex.lab = 2, cex.axis=1.5)
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey", lwd = 2)
points(moa_tbl$YEAR, moa_tbl$types_pmw, col = rgb(1,0,0,.5), pch = 18, cex = 1.3)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2, xaxt = "n")
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
# dev.off()
par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(1,1))
# Chunk 17
(p1 <- collex(collex_input, corpsize = sum(coca$Freq), am = "odds") %>% ggplot(aes(x = log1p(OBS), y = log1p(COLL.STR.ODDS), label = COLLEX, col = log1p(OBS))) + geom_text() + theme_bw() + xlab("Log odds ratio") + ylab("Log Frequency") + scale_color_continuous(low = rgb(0,.7,1,.4), high = "black") + guides(col = 'none') + ggtitle("COCA") +theme(plot.title = element_text(face = "bold", hjust = 0.5)))
(p2 <- collex(as.data.frame(d_tbl), corpsize = 1805183579, am = "odds") %>% ggplot(aes(x = log1p(OBS), y = log1p(COLL.STR.ODDS), label = COLLEX, col = log1p(OBS))) + geom_text() + theme_bw() + xlab("Log odds ratio") + ylab("Log Frequency") + scale_color_continuous(low = rgb(0,.7,1,.4), high = "black") + guides(col = 'none') + ggtitle("ENCOW") + theme(plot.title = element_text(face = "bold", hjust = 0.5)))
p1 | p2
# ggsave("collex_moa_coca_encow.png", height = 7, width = 13)
# Chunk 19: distsem
# import the model
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
# matrix of terms occurring in [mother of all X]'s open slot
cosine_dist_matrix <- cosineDist(model[[moa_lemmas$Lemma, average = FALSE]], model[[moa_lemmas$Lemma, average = FALSE]])
# multidimensional scaling
cosine_dists <- cosine_dist_matrix %>% cmdscale() %>% as.data.frame() %>% rownames_to_column() %>% setNames(c("lemma", "V1", "V2"))
# alternative: t-SNE
cosine_rtsne <- cosine_dist_matrix %>% Rtsne::Rtsne()
# we use Partitioning Around Medioids (PAM) to
# identify a small number of clusters (here: 3).
# As the results are not really meaningful, we have
# refrained from including it in the final analysis though.
# get PAM clusters
# for(i in 2:10) {
#   print(pam(cosine_dists, i)$silinfo$avg.width)
# }
#
pams <- pam(cosine_dists, 3)$clustering
# add frequency information
moa_freqs <- moa$lemma %>% table %>% as_tibble() %>% setNames(c("lemma", "n"))
# combine with MDS results
cosine_dists <- left_join(cosine_dists, moa_freqs)
# add log frequency
cosine_dists$LogFreq <- log1p(cosine_dists$n)
# 3 clusters
cosine_dists$clusters <- pams
# add Rtsne
cosine_dists <- cbind(cosine_dists, setNames(as.data.frame(cosine_rtsne$Y), c("dim1", "dim2")))
# visualize
# add one column that only serves to increase the font
# size of the remaining items (only for print version)
cosine_dists <- rbind(cosine_dists,
data.frame(lemma = "",
V1 = 0,
V2 = 0,
n = 0,
LogFreq = 0.3,
clusters = 1,
dim1 = 0, dim2 = 0))
set.seed(1994)
ggplot(cosine_dists, aes(x = V1, y = V2, label = lemma, size = LogFreq, col = factor(clusters))) +
geom_text_repel(max.overlaps = 15) +
guides(col = "none", size = "none") + theme_bw() +
# theme(axis.text = element_text(size = 18)) +
# theme(axis.title = element_text(size = 18)) +
# theme(strip.text = element_text(size = 18)) +
# theme(legend.title = element_text(size = 18, face = "bold")) +
# theme(text = element_text(size = 18)) +
scale_color_viridis_d() + ylab("dim2") + xlab("dim1")
# ggsave("distsem_moa_word2vec.png", width = 7, height = 6, dpi=500)
# use RTsne instead
set.seed(1994)
ggplot(cosine_dists, aes(x = dim1, y = dim2, label = lemma, size = LogFreq)) +
geom_text_repel(max.overlaps = 15) +
guides(size = "none") + theme_bw() +
# theme(axis.text = element_text(size = 18)) +
# theme(axis.title = element_text(size = 18)) +
# theme(strip.text = element_text(size = 18)) +
# theme(legend.title = element_text(size = 18, face = "bold")) +
# theme(text = element_text(size = 18)) +
scale_color_viridis_d() + ylab("dim2") + xlab("dim1")
# ggsave("distsem_moa_word2vec_tsne.png", width = 7, height = 6, dpi=500)
mother <- cosineDist(model[[c("mother", moa_lemmas$Lemma), average = FALSE]], model[[c("mother", moa_lemmas$Lemma), average = FALSE]])
mother <- as.data.frame(mother)
# png("mothervsrest.png", width = 6.5, height = 5, un = "in", res = 300)
mother[,which(colnames(mother)=="mother")] %>% hist(main = expression(paste("Cosine distance between ", italic("mother "), "and all X items")))
l <- list()
for(i in 1:100) {
spl <- sample(rownames(model), 1000)
l[[i]] <-cosineDist(model[[spl, average = F]], model[[spl, average = F]])
}
l_mean <- Reduce("+", l) / length(l)
l_sd   <- pbapply::pbapply(simplify2array(l), 1:2, sd)
tibble(mean = l_mean, sd = l_sd)
tibble(mean = l_mean, sd = l_sd) + geom_bar(aes( x = l_mean))
tibble(mean = l_mean, sd = l_sd) %>% ggplot() + geom_bar(aes( x = l_mean))
tibble(mean = l_mean, sd = l_sd) %>% ggplot() + geom_bar(aes( x = mean ))
tibble(mean = l_mean, sd = l_sd) %>% ggplot(aes(x = mean))
tibble(mean = l_mean, sd = l_sd)
l_mean
tibble(mean = unlist(l_mean), sd = unlist(l_sd))
tibble(mean = unlist(unname(l_mean)), sd = unlist(unname(l_sd)))
unlist(unname(l_mean))
as_vector(unlist(unname(l_mean)))
unlist(unlist(unname(l_mean)))
unlist(unlist(unname(l_mean))) %>% str
hist(l_mean)
hist(l_mean)
max(l_mean)
hist(l_mean)
l[[1]]
hist(l[[1]])
hist(l[[2]])
hist
max(l)
max(unlist(l))
max(unlist(l))
hist(l_mean)
saveRDS(mean, "mean.Rds")
saveRDS(l, "mean.Rds")
#saveRDS(l, "mean.Rds")
l <- readRDS("mean.Rds")
l_mean <- Reduce("+", l) / length(l)
hist(l_mean)
max(unlist(l))
hist(l_mean)
unlist(l) %>% hist
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode,"rtvs"), "data.table")
# Chunk 2: sessionInfo
sessionInfo()
# Chunk 3: packages
# install CRAN packages (if not yet installed)
sapply(c("data.table", "tidyverse", "devtools", "readxl", "kableExtra", "ngram", "networkD3", "igraph", "network", "patchwork", "koRpus", "pbapply", "tidytext", "cluster", "ggrepel", "animation", "vroom", "ggrepel", "Rtsne", "DT"), function(x) if(!is.element(x, installed.packages())) install.packages(x, dependencies = T, repos = "http://cran.us.r-project.org"))
# install non-CRAN packages (if not yet installed)
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
# if this doesn't work, check sfla.ch for the package
if(!is.element("collostructions", installed.packages())) {
install.packages("https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz", repos = NULL)
}
# install "concordances" if not yet installed
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances", ref = "f4ca785
")
}
# install "wordVectors" if not yet installed
if(!is.element("wordVectors", installed.packages())) {
devtools::install_github("bmschmidt/wordVectors")
}
# load "concordances"
library(concordances)
library(tidyverse)
library(readxl)
library(data.table)
library(kableExtra)
library(collostructions)
library(wordVectors)
library(vroom)
library(ggrepel)
library(cluster)
library(patchwork)
library(DT)
# Chunk 4
# read data
moa <- read_xlsx("../data/motherofall_COCA.xlsx")
# full frequency list cannot be shared publicly
# for license reasons, hence we work with the
# list containing only the lemmas occurring in
# mother of all
#coca <- fread("../coca_2017_lemma_frequency_list.txt", quote = "")
coca <- fread("../data/coca_moa_lemma_frequencies.csv")
# replace whitespaces in column names
colnames(moa) <- gsub(" ", "_", colnames(moa))
colnames(coca) <- c("No", "Lemma", "Freq")
# omit false hits
moa <- subset(moa, keep=="y")
# types, tokens, and hapax legomena overall
moa_tbl1 <- moa %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(Freq = "n") ) %>% arrange(desc(Freq))
tibble(
Tokens = sum(moa_tbl1$Freq),
Types = nrow(moa_tbl1),
"Hapax Legomena" = length(which(moa_tbl1$Freq==1))
)
# generate input for collostructional analysis
moa_lemmas <- moa$lemma %>% table %>% sort(decreasing = T) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_lemmas) <- c("Lemma", "Freq_in_cxn")
all_lemmas <- coca[,Lemma, Freq]
setcolorder(all_lemmas, c("Lemma", "Freq"))
collex_input <- join.freqs(moa_lemmas, as.data.frame(all_lemmas), all = F)
colnames(collex_input) <- c("Lemma", "cxn_freq", "cxn_all")
collex_input <- subset(collex_input, cxn_all != 0)
left_join(collex(collex_input, corpsize = sum(coca$Freq), delta.p = T),
select(collex(collex_input, corpsize = sum(coca$Freq), am = "odds"), COLLEX, COLL.STR.ODDS)) %>% DT::datatable()
# %>% write_excel_csv("simple_collexeme_analysis.csv")
# relative frequency ------------------------------------------------------
# get COCA frequencies
coca_freq <- read_xlsx("../data/COCA2017_total_frequencies.xlsx")
# tabulate mother frequency
moa_tbl <- table(moa$Year) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_tbl) <- c("YEAR", "Freq")
moa_tbl$YEAR <- as.numeric(moa_tbl$YEAR)
moa_tbl <- left_join(coca_freq, moa_tbl, by = "YEAR")
moa_tbl$pmw <- (moa_tbl$Freq / moa_tbl$TOTAL) * 1e06
# plot
# png("mother_of_all_coca_freq.png", width = 6.5, height = 5, un = "in", res = 300)
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = "Token and type frequencies")
#main = expression(paste("[", italic("mother of all"), " X], COCA")))
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey")
# dev.off()
# types per decade
moa_types <- moa %>% group_by(Decade) %>% summarise(
types = length(unique(lemma)),
n = n()
)
# types per year
moa_types_year <- moa %>% group_by(Year) %>% summarise(
types = length(unique(lemma))
)
# add to table with total frequencies
moa_tbl <- left_join(moa_types_year, moa_tbl, by = c("Year" = "YEAR"))
moa_tbl <- rename(moa_tbl, "YEAR" = "Year")
moa_tbl$types_pmw <- (moa_tbl$types / moa_tbl$TOTAL) * 1e6
# coca_freq per dcade
coca_freq$Decade <- floor(coca_freq$YEAR/10)*10
coca_freq_decade <- coca_freq %>% group_by(Decade) %>% summarise(
n = sum(TOTAL)
)
# types per decade
moa_types <- left_join(moa_types, coca_freq_decade)
moa_types$rel <- moa_types$types / moa_types$n
moa_types$rel %>% plot
moa_types$ttr <- moa_types$types / moa_types$n
# distribution of hapaxes
hapaxes <- table(moa$lemma) %>% as.data.frame %>% filter(Freq==1) %>% select(Var1) %>% as.vector
hapaxes <- as.character(hapaxes$Var1)
moa$hapax <- ifelse(moa$lemma %in% hapaxes, "y", "n")
moa_hapaxes <- moa %>% group_by(Decade) %>% summarise(
hapaxes = length(which(hapax=="y")),
n = n()
)
# plot potential productivity
moa_hapaxes$pp <- moa_hapaxes$hapaxes / moa_hapaxes$n
par(mfrow = c(1,3))
#png("types_tokens_mother_COCA.png", width = 12, height = 4, un = "in", res = 300)
par(mfrow=c(1,3))
par(mar = c(5.1, 5.1, 5.1, 2.1))
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
ylab = "Frequency per million words", xlab = "Year",
main = "Token and type frequencies",
#main = expression(paste(bold("["), bolditalic("mother of all"), bold(" X], COCA"))),
cex = 2, cex.lab = 2, cex.axis=1.5)
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey", lwd = 2)
points(moa_tbl$YEAR, moa_tbl$types_pmw, col = rgb(1,0,0,.5), pch = 18, cex = 1.3)
plot(moa_types$Decade, moa_types$ttr,
type = "b", pch=18,
ylab = "Types / Tokens", xlab = "Decade",
main = "Type-Token Ratio, COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2,
xaxt = "n"
)
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
ylab = "Proportion hapaxes", xlab = "Decade",
main = "Potential productivity \n (proportion of hapax legomena), COCA",
lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=2, xaxt = "n")
axis(1, at = c(1990, 2000, 2010), cex.axis=2)
# dev.off()
par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(1,1))
# Chunk 5
(p1 <- collex(collex_input, corpsize = sum(coca$Freq), am = "odds") %>% ggplot(aes(x = log1p(OBS), y = log1p(COLL.STR.ODDS), label = COLLEX, col = log1p(OBS))) + geom_text() + theme_bw() + xlab("Log odds ratio") + ylab("Log Frequency") + scale_color_continuous(low = rgb(0,.7,1,.4), high = "black") + guides(col = 'none') + ggtitle("COCA") +theme(plot.title = element_text(face = "bold", hjust = 0.5)))
# ggsave("collex_moa_coca_encow.png", height = 7, width = 13)
# Chunk 7: import
d <- getNSE("../data/mother_of_all.xml", xml = TRUE, context_tags = FALSE, verbose = FALSE)
# Chunk 8: anno
# write_excel_csv(d, "mother_of_all_ENCOW.csv")
d <- read_xlsx("../data/mother_of_all_ENCOW.xlsx")
# Chunk 9: dw
d <- filter(d, keep == "y")
# Chunk 10
# frequency table
d_tbl <- d %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(Freq = "n")) %>% arrange(desc(Freq))
# overview table
tibble(
# types
Types = nrow(d_tbl),
# tokens
Tokens = sum(d_tbl$Freq),
# hapax legomena
"Hapax Legomena" = length(which(d_tbl$Freq==1))
) %>% kbl() %>% kable_material(c("striped", "hover"))
# Chunk 15
# re-import
d_tbl <- read_csv("../data/mother_of_all_with_encow_frequencies.csv")
# Chunk 16: excludethis
# omit one case where corpus frequency is
# smaller than cxn frequency
d_tbl <- subset(d_tbl, d_tbl[,2] <= d_tbl[,3])
# Chunk 17: collex
# sum(encow$Freq): 1805183579
# perform collexeme analysis
left_join(collex(as.data.frame(d_tbl), corpsize = 1805183579, delta.p = TRUE),
select(collex(as.data.frame(d_tbl), corpsize = 1805183579, am = "odds"), COLLEX, COLL.STR.ODDS)) %>% DT::datatable()  #kbl() %>%
#kable_material(c("striped", "hover")) %>% scroll_box(width = "800px", height = "200px")
# Chunk 18
(p2 <- collex(as.data.frame(d_tbl), corpsize = 1805183579, am = "odds") %>% ggplot(aes(x = log1p(OBS), y = log1p(COLL.STR.ODDS), label = COLLEX, col = log1p(OBS))) + geom_text() + theme_bw() + xlab("Log odds ratio") + ylab("Log Frequency") + scale_color_continuous(low = rgb(0,.7,1,.4), high = "black") + guides(col = 'none') + ggtitle("ENCOW") + theme(plot.title = element_text(face = "bold", hjust = 0.5)))
# Chunk 20: distsem
# import the model
model <- readRDS("/Users/stefanhartmann/sciebo/Projekte/snowclones/word2vec/model.Rds")
# matrix of terms occurring in [mother of all X]'s open slot
cosine_dist_matrix <- cosineDist(model[[moa_lemmas$Lemma, average = FALSE]], model[[moa_lemmas$Lemma, average = FALSE]])
# multidimensional scaling
cosine_dists <- cosine_dist_matrix %>% cmdscale() %>% as.data.frame() %>% rownames_to_column() %>% setNames(c("lemma", "V1", "V2"))
# alternative: t-SNE
cosine_rtsne <- cosine_dist_matrix %>% Rtsne::Rtsne()
# we use Partitioning Around Medioids (PAM) to
# identify a small number of clusters (here: 3).
# As the results are not really meaningful, we have
# refrained from including it in the final analysis though.
# get PAM clusters
# for(i in 2:10) {
#   print(pam(cosine_dists, i)$silinfo$avg.width)
# }
#
pams <- pam(cosine_dists, 3)$clustering
# add frequency information
moa_freqs <- moa$lemma %>% table %>% as_tibble() %>% setNames(c("lemma", "n"))
# combine with MDS results
cosine_dists <- left_join(cosine_dists, moa_freqs)
# add log frequency
cosine_dists$LogFreq <- log1p(cosine_dists$n)
# 3 clusters
cosine_dists$clusters <- pams
# add Rtsne
cosine_dists <- cbind(cosine_dists, setNames(as.data.frame(cosine_rtsne$Y), c("dim1", "dim2")))
# visualize
# add one column that only serves to increase the font
# size of the remaining items (only for print version)
cosine_dists <- rbind(cosine_dists,
data.frame(lemma = "",
V1 = 0,
V2 = 0,
n = 0,
LogFreq = 0.3,
clusters = 1,
dim1 = 0, dim2 = 0))
set.seed(1994)
ggplot(cosine_dists, aes(x = V1, y = V2, label = lemma, size = LogFreq, col = factor(clusters))) +
geom_text_repel(max.overlaps = 15) +
guides(col = "none", size = "none") + theme_bw() +
# theme(axis.text = element_text(size = 18)) +
# theme(axis.title = element_text(size = 18)) +
# theme(strip.text = element_text(size = 18)) +
# theme(legend.title = element_text(size = 18, face = "bold")) +
# theme(text = element_text(size = 18)) +
scale_color_viridis_d() + ylab("dim2") + xlab("dim1")
# ggsave("distsem_moa_word2vec.png", width = 7, height = 6, dpi=500)
# use RTsne instead
set.seed(1994)
ggplot(cosine_dists, aes(x = dim1, y = dim2, label = lemma, size = LogFreq)) +
geom_text_repel(max.overlaps = 15) +
guides(size = "none") + theme_bw() +
# theme(axis.text = element_text(size = 18)) +
# theme(axis.title = element_text(size = 18)) +
# theme(strip.text = element_text(size = 18)) +
# theme(legend.title = element_text(size = 18, face = "bold")) +
# theme(text = element_text(size = 18)) +
scale_color_viridis_d() + ylab("dim2") + xlab("dim1")
# ggsave("distsem_moa_word2vec_tsne.png", width = 7, height = 6, dpi=500)
# Chunk 21
mother <- cosineDist(model[[c("mother", moa_lemmas$Lemma), average = FALSE]], model[[c("mother", moa_lemmas$Lemma), average = FALSE]])
mother <- as.data.frame(mother)
# png("mothervsrest.png", width = 6.5, height = 5, un = "in", res = 300)
mother[,which(colnames(mother)=="mother")] %>% hist(main = expression(paste("Cosine distance between ", italic("mother "), "and all X items")))
# dev.off()
unlist(l) %>% hist
#saveRDS(l, "mean.Rds")
l <- readRDS("mean.Rds")
unlist(l) %>% hist
spl <- sample(rownames(model), 10000)
l[[i]] <-cosineDist(model[[spl, average = F]], model[[spl, average = F]])
spl_mean <- cosineDist(model[[spl, average = F]], model[[spl, average = F]])
hist(spl_mean)
max(spl_mean)
?collex
