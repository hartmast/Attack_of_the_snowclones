---
title: "The mother of all X"
author: "Authors"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: flatly
    highlight: tango
    toc: true
    toc_float: true
    collapsed: false
    df_print: paged
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode,"rtvs"), "data.table")
```

## Preliminaries

session info:

```{r sessionInfo, message = FALSE, warning = FALSE}
sessionInfo()
```

Install and load packages

```{r packages, warning = FALSE, message = FALSE}
# install CRAN packages (if not yet installed)
sapply(c("data.table", "tidyverse", "devtools", "readxl", "kableExtra", "ngram", "networkD3", "igraph", "network", "patchwork", "koRpus", "pbapply", "tidytext", "cluster", "ggrepel", "animation"), function(x) if(!is.element(x, installed.packages())) install.packages(x, dependencies = T))
# install non-CRAN packages (if not yet installed)
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
# if this doesn't work, check sfla.ch for the package
if(!is.element("collostructions", installed.packages())) {
  install.packages("https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz", repos = NULL)
}
# install "concordances" if not yet installed
if(!is.element("concordances", installed.packages())) {
  devtools::install_github("hartmast/concordances", ref = "f4ca785
")
}
# load "concordances"
library(concordances)
library(tidyverse)
library(readxl)
library(data.table)
library(kableExtra)
library(collostructions)
```

# ENCOW

## Data retrieval

The data were retrieved from the NoSketchEngine instance of the COW corpora (https://www.webcorpora.org/) on Sept 27, 2019, using the ENCOW16B "World Englishes" corpus. The query was:

```{r queries, eval=FALSE, message = FALSE, warning = FALSE}
[word="[Tt]he"] "mother" "of" "all" []
```

The data were exported to the XML file mother_of_all.xml, which is imported in the subsequent step.

```{r import, message = FALSE, warning = FALSE}
d <- getNSE("../data/mother_of_all.xml", xml = TRUE, context_tags = FALSE, verbose = FALSE)
```


## Annotation

The concordance is exported for annotation, the annotated file is then read in.

```{r anno, message = FALSE, warning = FALSE}
# write_excel_csv(d, "mother_of_all_ENCOW.csv")
d <- read_xlsx("../data/mother_of_all_ENCOW.xlsx")
```

## Data wrangling

We only keep the instances manually tagged as keep == "y", excluding false hits and doubtful cases.

```{r dw}
d <- filter(d, keep == "y")
```


## Types, tokens, hapax legomena

```{r}
# frequency table
d_tbl <- d %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(lemma = ".", Freq = "n")) %>% arrange(desc(Freq))
# overview table
tibble(
  # types
  Types = nrow(d_tbl),
  # tokens
  Tokens = sum(d_tbl$Freq),
# hapax legomena
  "Hapax Legomena" = length(which(d_tbl$Freq==1))
) %>% kbl() %>% kable_material(c("striped", "hover"))
```

## Collostructional analysis

For performing a collostructional analysis, we have to know how often a lemma attested in the open slot of the *mother of all* construction occurs in the ENCOW corpus as a whole. For this purpose, we read in the ENCOW word list (available at [webcorpora.org](https://www.webcorpora.org/opendata/frequencies/english/)).

```{r wordlist, message = FALSE, cache = TRUE, eval = FALSE}
# not in repository,
# available at webcorpora.org after registration
# frequencies for relevant hits available at ../data/mother_of_all_with_encow_frequencies.csv
encow <- fread("/Volumes/My Passport/ENCOW word lists/encow16ax.lp.tsv",
               header = F)
# 
# head(encow)
# 
# # only nouns
# encow <- encow[V2 %in% c("NN", "NE")]
# 
# head(encow)
```


This is a huge database, but we only need nouns and adjectives, so we drop the rest in order to speed up the next calculations. Also, we add more self-explanatory column names:

```{r wlwrangling, cache = TRUE, eval = FALSE}
# only nouns
encow <- encow[V2 %in% c("NN", "NE")]
colnames(encow) <- c("Lemma", "POS", "Freq")
# if something is attested both as NN and
# NE, sum them up
encow <- encow[, sum(Freq), by = Lemma]
setnames(encow, old = "V1", new = "Freq")
```

We compile a frequency table from our *mother of all* concordance `d` and combine it with the corpus frequencies in the `encow` table.

```{r joinfreqs, eval = FALSE}
# get frequencies
d_tbl <- d %>% select(lemma) %>% table %>% sort(decreasing = T) %>% 
  as.data.frame(stringsAsFactors = F)
colnames(d_tbl) <- c("Lemma", "Freq_in_cxn")
# join tables
d_tbl <- left_join(d_tbl, encow, by = "Lemma")
```

```{r include = FALSE, eval = FALSE}
# export
write_excel_csv(d_tbl, "mother_of_all_with_encow_frequencies.csv")
```

```{r include = FALSE}
# re-import
d_tbl <- read_csv("../data/mother_of_all_with_encow_frequencies.csv")
```

These data are not without noise - ENCOW's lemmatization is of course not perfect, but we can still expect that the relationships between construction frequencies and corpus frequencies of the words in question are roughly representative of their "actual" relationship in everyday use, at least in the text types represented in the corpus. However, given that the lemmatization is not perfect, there can be cases where the corpus frequency is lower than the construction frequency. This is of course not possible - if a word occurs, say, three times in a specific construction in corpus, its total frequency in the corpus cannot be lower than three! In one instance, however, this is the case in our data. The reason for this is that our concordance was lemmatized manually while for ENCOW, we rely on the automatic lemmatization. As this only affects one single attestation, we just exclude it.

```{r excludethis}
# omit one case where corpus frequency is
# smaller than cxn frequency
d_tbl <- subset(d_tbl, d_tbl[,2] <= d_tbl[,3])
```

Next, we perform a collexeme analysis using Flach's `collostructions` package.

```{r collex}
# sum(encow$Freq): 1805183579
# perform collexeme analysis
collex(d_tbl, corpsize = 1805183579) %>% kbl() %>%  
   kable_material(c("striped", "hover")) %>% scroll_box(width = "800px", height = "200px")
```


# COCA

```{r}
# read data
moa <- read_xlsx("../data/motherofall_COCA.xlsx")
# full frequency list cannot be shared publicly
# for license reasons, hence we work with the
# list containing only the lemmas occurring in 
# mother of all
#coca <- fread("../coca_2017_lemma_frequency_list.txt", quote = "")
coca <- fread("../data/coca_moa_lemma_frequencies.csv")
# replace whitespaces in column names
colnames(moa) <- gsub(" ", "_", colnames(moa))
colnames(coca) <- c("No", "Lemma", "Freq")
# omit false hits
moa <- subset(moa, keep=="y")
# types, tokens, and hapax legomena overall
moa_tbl1 <- moa %>% select(lemma) %>% table %>% as_tibble() %>% rename(c(lemma = ".", Freq = "n") ) %>% arrange(desc(Freq))
tibble(
  Tokens = sum(moa_tbl1$Freq),
  Types = nrow(moa_tbl1),
  "Hapax Legomena" = length(which(moa_tbl1$Freq==1))
)
# generate input for collostructional analysis
moa_lemmas <- moa$lemma %>% table %>% sort(decreasing = T) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_lemmas) <- c("Lemma", "Freq_in_cxn")
all_lemmas <- coca[,Lemma, Freq]
setcolorder(all_lemmas, c("Lemma", "Freq"))
collex_input <- join.freqs(moa_lemmas, as.data.frame(all_lemmas), all = F)
colnames(collex_input) <- c("Lemma", "cxn_freq", "cxn_all")
collex_input <- subset(collex_input, cxn_all != 0)
collex(collex_input, corpsize = sum(coca$Freq)) # %>% write_excel_csv("simple_collexeme_analysis.csv")
# relative frequency ------------------------------------------------------
# get COCA frequencies
coca_freq <- read_xlsx("../data/COCA2017_total_frequencies.xlsx")
# tabulate mother frequency
moa_tbl <- table(moa$Year) %>% as.data.frame(stringsAsFactors = F)
colnames(moa_tbl) <- c("YEAR", "Freq")
moa_tbl$YEAR <- as.numeric(moa_tbl$YEAR)
moa_tbl <- left_join(coca_freq, moa_tbl, by = "YEAR")
moa_tbl$pmw <- (moa_tbl$Freq / moa_tbl$TOTAL) * 1e06
# plot
# png("mother_of_all_coca_freq.png", width = 6.5, height = 5, un = "in", res = 300)
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
     ylab = "Frequency per million words", xlab = "Year",
     main = expression(paste("[", italic("mother of all"), " X], COCA")))
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey")
# dev.off()
# types per decade
moa_types <- moa %>% group_by(Decade) %>% summarise(
  types = length(unique(lemma)),
  n = n()
)
# types per year
moa_types_year <- moa %>% group_by(Year) %>% summarise(
  types = length(unique(lemma))
)
# add to table with total frequencies
moa_tbl <- left_join(moa_types_year, moa_tbl, by = c("Year" = "YEAR"))
moa_tbl <- rename(moa_tbl, "YEAR" = "Year")
moa_tbl$types_pmw <- (moa_tbl$types / moa_tbl$TOTAL) * 1e6
# coca_freq per dcade
coca_freq$Decade <- floor(coca_freq$YEAR/10)*10
coca_freq_decade <- coca_freq %>% group_by(Decade) %>% summarise(
  n = sum(TOTAL)
)
# types per decade
moa_types <- left_join(moa_types, coca_freq_decade)
moa_types$rel <- moa_types$types / moa_types$n
moa_types$rel %>% plot
moa_types$ttr <- moa_types$types / moa_types$n
# distribution of hapaxes
hapaxes <- table(moa$lemma) %>% as.data.frame %>% filter(Freq==1) %>% select(Var1) %>% as.vector
hapaxes <- as.character(hapaxes$Var1)
moa$hapax <- ifelse(moa$lemma %in% hapaxes, "y", "n")
moa_hapaxes <- moa %>% group_by(Decade) %>% summarise(
  hapaxes = length(which(hapax=="y")),
  n = n()
)
# plot potential productivity
moa_hapaxes$pp <- moa_hapaxes$hapaxes / moa_hapaxes$n
par(mfrow = c(1,3))
#png("types_tokens_mother_COCA.png", width = 12, height = 4, un = "in", res = 300)
par(mfrow=c(1,3))
par(mar = c(5.1, 5.1, 5.1, 2.1))
plot(moa_tbl$YEAR, moa_tbl$pmw, pch = 20, col = "blue",
     ylab = "Frequency per million words", xlab = "Year",
     main = expression(paste(bold("["), bolditalic("mother of all"), bold(" X], COCA"))),
     cex = 2, cex.lab = 2, cex.axis=1.5)
abline(lm(moa_tbl$pmw ~ moa_tbl$YEAR), lty = 2, col = "darkgrey", lwd = 2)
points(moa_tbl$YEAR, moa_tbl$types_pmw, col = rgb(1,0,0,.5), pch = 18, cex = 1.3)
plot(moa_types$Decade, moa_types$ttr,
     type = "b", pch=18,
     ylab = "Types / Tokens", xlab = "Decade",
     main = "Type-Token Ratio, COCA",
     lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5)
plot(moa_hapaxes$Decade, moa_hapaxes$pp, type = "b", pch=18,
     ylab = "Proportion hapaxes", xlab = "Decade",
     main = "Potential productivity \n (proportion of hapax legomena), COCA",
     lwd = 2, col = "blue", cex = 2, cex.lab = 2, cex.axis=1.5)
# dev.off()
par(mar = c(5.1, 4.1, 4.1, 2.1))
par(mfrow=c(1,1))
```

